<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<title>Jan Hannig</title>
<link href="css.css" rel="stylesheet" type="text/css" />
</head>
<a name="top" id="top"></a>
<!--obal -->
<div id="obal">
<!--hlavicka-->
<div id="hlavicka"><a href="index.html"><img src="_img/hlavicka.gif" width="800" height="90" border="0" /></a></div>
<!--hlavicka end-->
<!--navigace-->
<div id="navigace" >
<a href="index.html">welcome</a>
<a href="research.html">research</a>
<a href="cv.html">cv</a>
<a href="teaching.html">teaching</a>
<a href="personal.html">personal</a>
</div>
<!--navigace end-->
  <div id="clear"></div>
<!--obsah_top-->
<div id="obsah_top4">
<div id="blok1"></div>
<div id="blok">
  <h3>&nbsp;</h3>
  <p>statement </p>
  <p><a href="r_publications.html">publications</a></p>
  <p><a href="r_selected.html">selected  </a></p>
  <p><a href="r_download.html">code for download</a></p>
</div>
<div id="blok3"></div>
<div id="blok4"></div>
<div id="blok5"></div>
</div>
<!--obsah_top end-->
<div id="clear"></div>
<!--obsah_top-->
<div id="obsah_navigace">
  

</div>
<!--obsah_top end-->
<!--obsah-->
<div id="obsah">
<div id="levo1">
  <h1>Research statement </h1>
  <p>During my career,  I developed rather diverse research interests in data science, theoretical statistics and probability. In particular there are four major areas in which I have made multiple contributions: generalized fiducial inference, methodology and theory for data integration, analytical probability and application to engineering, finance, genomics, and forensic science. My contributions and future plans are summarized by area below. </p>
  <p>&nbsp;</p>
  <p><strong>Generalized Fiducial Inference and related topics<br />
    (</strong>funded by NSF grants DMS 1007520, 0707037, 1512945, and 1916115)</p>
  <p>A large percentage of my current effort is concerned with studying theoretical properties of generalized fiducial inference. R. A. Fisher's fiducial inference has been the subject of many discussions and controversies ever since he introduced the idea during the 1930s. The idea experienced a bumpy ride, to say the least, during its early years and one can safely say that it eventually fell into disfavor among mainstream statisticians. However, it appears to have made a resurgence recently under various labels such as generalized inference, confidence distributions, Dempster-Shafer calculus and its derivatives. In these new guises fiducial inference has proved to be a useful tool for deriving statistical procedures for problems where frequentist methods with good properties were previously unavailable.</p>
  <p>The aim of my work is to revisit the fiducial idea of Fisher from a fresh new angle. I do not attempt to derive a new paradox free theory of fiducial inference as I do not believe this is possible. Instead, with minimal assumptions I present a new simple fiducial recipe that can be applied to conduct statistical inference via the construction of generalized fiducial distributions. This recipe is designed to be fairly easily implementable in various practical applications, and can be applied regardless of the dimension of the parameter space, e.g., including nonparametric problems. I term the resulting inference generalized fiducial inference (GFI). A reader interested in learning more about generalized fiducial inference can consult our <a href="http://www.tandfonline.com/doi/full/10.1080/01621459.2016.1165102">review article</a>  and <a href="download/FiducialShortCourse2018.pdf">short course</a> slides.</p>
  <p>From the very beginning our work has been motivated by important applications in areas such as pharmaceutical statistics and metrology. Jointly with several of my students  and collaborators at other institutions we applied the generalized fiducial methodology to important applied problems with a great success. In addition to methodological research I have also analyzed mathematical properties of generalized fiducial distribution proving that generalized fiducial distribution often gives rise to statistical procedures that have good statistical properties asymptotically. Fiducial based statistical procedures are also very competitive for small samples. This is shown by mounting evidence from several simulation studies giving practitioners an exciting new data analysis tool. </p>
  <p>In particular, my contributions naturally cluster into four areas: First, is the definition and theoretical properties of generalized fiducial inference. My initial significant contribution was in a 2006 paper that connected fiducial inference to a new field of generalized inference sparking a number of subsequent publications. The current formal definition of generalized fiducial inference can be found in a 2016 review article that contains a number of useful result and formulas. In a series of publications my students and I have provided proof of Bernstein-von Mises theorems establishing asymptotic correctness of generalized fiducial inference for a large class of parametric models. We are currently in the process of studying higher order asymptotic results. Additionally, my coauthors and I show how generalized fiducial distribution can be used for prediction, connect generalized fiducial distribution with another growing field of confidence distributions, and address computational issues.</p>
  <p>Second area of interest is application of generalized fiducial inference to statistical problems of practical interest. For example GFI provides statistical tools for inference in linear mixed models that have properties very favorable compared to other methodologies available in the literature. Other applications include inference for extremes, a novel method for volatility estimation in high frequency financial data, and an application to psychology (item response modeling). Finally, several papers address specific applications in measurement science. Some of these ideas have a direct impact on government policy-making with regard to international inter-laboratory experiments and assessment of measurement capabilities by the U. S. National Institute of Standards and Technology (NIST). Current applications of interest include the use of fiducial idea in analysis of genetics and RNASeq like data. </p>
  <p>Third area is the use of the generalized fiducial distribution for model selection and non-parametric models.  The flexibility of generalized fiducial inference allows us to move beyond parametric problems, e.g., a large sparse linear systems and estimation of a non-parametric survival function. As a first step in this direction we investigates the use of generalized fiducial inference for constructing wavelet regression confidence intervals and a generalized fiducial solution to the ultra-high-dimensional regression problem using EBIC-like penalty. Current projects are approaching this problem from a completely new angle; doing model selection without the use of an arbitrary penalty. We have successfully completed a pilot project on high dimensional regression and currently pursue a multidimensional time series model selection. </p>
  <p>The last area is related to practical computation of fiducial distribution. Initially, the main computational tool for generalized fiducial inference was Markov Chain Monte Carlo and Sequential Monte Carlo. Recently, we have also developed an algorithm that can implement fiducial distribution for massive data set using divide and conquer approach. However, historically each application fiducial inference required a particular implementation of a computational procedure. In order for fiducial approaches to be useful to data scientist, there is a need to develop a general purpose probabilistic programing software that will be applicable to most data science problem. In particular, computation of fiducial distribution requires an inversion of a data generating process. We are currently pursuing approximating this inverse using a deep neural network.  While for any given statistical problem the neural network can be tuned to work well, the main challenge will be to obtain some tuning that would work well across a broad spectrum of  applications.</p>
  <p>&nbsp;</p>
  <p><strong>Big Data, Data Integration and SiZer<br />
    (</strong>funded by NSF grant IIS-1633074)<strong>    </strong></p>
  <p>Data science provides a natural place for collaborations between statisticians, computer scientists, and mathematicians. One of the current challenges is caused by data heterogeneity. This phenomenon is frequent in Big Data, because it naturally arises when data sets are merged.  So far there has been rather little thought or discussion within the quantitative communities (neither in statistics, nor elsewhere) about the impact of data set combination, yet that is a crucial issue. Integrative analysis of disparate data blocks measured on a common set of experimental subjects is an example of this  major challenge in modern data analysis. </p>
  <p>A natural goal of integrative analysis is simultaneous exploration of the joint and individual variation within each data block resulting in new insights. For instance, there is a strong desire to integrate the multiple genomic data sets in The Cancer Genome Atlas to characterize the common and also the unique aspects of cancer genetics and cell biology for each source. We introduce a method termed Angle-Based Joint and Individual Variation Explained capturing both joint and individual variation within each data block. </p>
  <p>AJIVE provides a major improvement over earlier approaches to this challenge in terms of a new conceptual understanding, much better adaption to data heterogeneity and a fast linear algebra computation. Moreover, the tools developed allow to compare several approximations of the data creating a scale space view. This can be use to better understand underlying common driving forces or on the opposite side of the spectrum to eliminate batch effects. </p>
  <p>Our future work will extend the AJIVE methodology to include more complex intermediate variation and provide theoretical studies of its properties. We also plan to apply this tool to various datasets and develop a supervised version of JIVE. </p>
  <p>Another basic questions in statistics is finding a functional relationship between predictors and response variables known under the technical term regression. When the relationship cannot be described by a simple function, e.g. line, a more flexible, non-parametric, method is sought. Such methods are generally require a selection of a smoothing parameter. At the turn of the millennium Chaudhury and Marron have argued that instead of selecting a single tuning parameter one should work with a number of them identifying features visible at different levels of smoothing. These features were distinguished using a large number of statistical tests summarized using a special graphics termed SiZer (Significant Zero crossing) map. Since then SiZer maps have found their use in many exploratory data analysis situations. <br />
    The fact that SiZer map is based on a large number of statistical tests requires an adjustment to make the map less susceptible to false positive, multiple testing adjustment. The original SiZer of Chaudhuri and Marron had an ad-hoc adjustment that made the original SiZer prone to false positive results. </p>
  <p>My first contribution to this area was to provide a rigorous multiple testing adjustment based on extreme value theory substantially improving the validity of SiZer maps. %I worked out a ``second order'' approximation to the extreme value distribution of the Gaussian random process implied by SiZer. <br />
    In order to make the SiZer idea practical beyond the original i.i.d. setup one needs to extend it to other models. My next contributions have concentrated on such extensions. For example we use quantile regression and M-estimation to provide a robust SiZer map capable of dealing with outliers and propose a version of a SiZer for dependent data. We also provided a tool for rigorous comparison of SiZer maps. <br />
    The general philosophy of SiZer, i.e., looking at the results of a statistical algorithm for number of possible tuning parameters and coupling it with a rigorous statistical test to make sense of the changes in the outputs, is definitely transferable to other data science applications.</p>
  <p>&nbsp;</p>
  <p><strong>Applications<br />
    (</strong>funded by NSF grants DMS 1016441 and ECCS 0700559) </p>
  <p>Another important active area of my interest is application of statistics and probability to engineering, finance, and biology. Here I have worked on several interesting applications. </p>
  <p>The first application I am part of is concerned with the modeling and simulation of extremely large networks using time-dependent partial differential equations (PDEs). In many applications, numerical simulation is the tool of choice for the design and evaluation of large networks. However, the computational overhead associated with direct simulation severely limits the size and complexity of networks that can be studied in this fashion. Performing numerical simulations of large stochastic networks has been widely recognized as a major hurdle to future progress in understanding and evaluating large networks. Our modeling approach is based on asymptotic analysis of a stochastic system that provides a probabilistic description of the network dynamics. This approach appears particularly promising for networks like a wireless ad hoc network. </p>
  <p>In this kind of network, nodes send to and receive from other nodes that are within transmission range. Transmission success is affected by interference; e.g., nodes are often so simple that they can receive only one message at a time, and propagation losses are often modeled by a power law dependence on distance. In this situation, we believe that it is possible to formulate the flow of information through the network using hydrodynamic scaling limits for the behavior of the individual packets or particles. The team working on this project contains an electrical engineer, probabilist and a pde specialist. In a series of papers we develop technical tools, provide a rigorous mathematical proof of convergence of the random process modeling a class of communication networks to the limiting PDE and apply the ideas to various network protocols.</p>
  <p>The second application is simultaneous target tracking. The main idea here is to provide an algorithm that, based on a limited information from sensors or images, provides a location (or sequence of locations called a track) for each of the targets with high fidelity. My student, collaborator at another institution and I provide a model based algorithm for tracking of multiple moving objects extracted from an image sequence allowing for birth, death, splitting and merging of targets. This is an important problem which finds numerous applications in science and engineering. From a somewhat different angle, another group of collaborators and I study a tracking of targets using sensors with limited communication capacity using information theoretic tools. </p>
  <p>The third application is financial data. The presence or absence of jumps in the financial time series data, such as stock prices has been of interest among researchers and practitioners due to the effect presence of jumps has on pricing of various financial instruments. We provide a new test for detecting jumps in financial time series. I also used the ideas of generalized fiducial inference and non-parametric smoothing to provide new statistical inference procedures for volatility in financial data. </p>
  <p>Lastly, my students, collaborators and I provided a statistical algorithm for detecting anthrax from laser induced spectroscopy data. We also have an article on detection of misclassified compounds in chemical libraries. </p>
  <p>Currently I am working with collaborators in biology; in particular statistical analysis of high throughput DNA sequencing data. One problem of interest is detecting changes in genome  in response to the environmental pressure. The techniques my student and I are currently applying combine SiZer type ideas with generalized fiducial and objective Bayesian methods. Another problem we are currently working on is basic analysis of uncertainties for a new sequencing method measuring lengths of segments between pre-determined sequences. Finally I am collaborating with researcher at NAtional Institute of Science and Techniology on development well calibrated Likelihood Ratios to summarize evidence found in a crime scene.</p>
  <p>&nbsp;</p>
  <p><strong>Analytical probability<br />
  </strong>(funded by NSF grant DMS 0504737) </p>
  <p>A large portion of my early career was spent working on problems from analytical probability.  The main area of my interest was small deviation for Gaussian processes, i.e., understanding the behavior of the probability that a stochastic process X(t) stays during a time interval [0,T] in a small ball of radius e around the origin. As e tends to 0, this probability clearly tends to zero and the question is at what rate?  Answers to small deviation questions are used in other fields of mathematics such as analysis of non-parametric Bayes estimators, quantization and metric entropy. My collaborators and I made contributions to the theory of small deviations under the L2 norm. we characterize the precise L2  small deviations for a large class of continuous Gaussian processes. We also provide a comparison theorem for lower tail of sums of positive random variables. </p>
  <p>Another area of interest was an analysis of several stochastic search algorithms related to simulated annealing. The convergence of simulated annealing has been established earlier by Hajek in the 1980s. Our work   uses an alternative simple approach based on the relative frequency simulated annealing spends in the various states of the system.  We also provide a particular type of rates of convergence not available before.  </p>
  <p>Finally, my dissertation studied the properties of filtrations supporting only purely discontinuous martingales. The main result could be paraphrased as follows: if all martingales have at least one jump then all the information available in the system is included in the timing and sizes of the jumps.</p>
  <p><a href="#top">top</a></p>
</div>
<div id="clear"></div>
</div>
<!--obsah end-->
<!--paticka-->
<div id="paticka">
<p>copyright &copy; Jan Hannig, designed by JanAltonDesign, 2008 </p>
</div>
<!--paticka end-->
</div>
<!--obal end-->
</body>
</html>
